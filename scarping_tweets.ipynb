{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04dca157",
   "metadata": {},
   "source": [
    "# Parsing data from twitter\n",
    "\n",
    "- Getting counts within time ranges and saving them into file time_ranges.pkl.\n",
    "- Creating a df_all dataframe, that contains rows labeled with timeperiod based on tweet count thresholds.\n",
    "- Collecting tweets within detected time ranges and saving into file balenciaga_nov.pkl.\n",
    "- Retreiving information on users whose tweets are collected into file users_balenciaga2_nov_additional.pkl.\n",
    "- Merging tweets and infirmation on users and saving into file balenciaga3.pkl."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c7fb96",
   "metadata": {},
   "source": [
    "# Libraries to import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efadf096",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037cbb4e",
   "metadata": {},
   "source": [
    "# Twitter tokens\n",
    "Hided tokens for security measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f0f2749",
   "metadata": {},
   "outputs": [],
   "source": [
    "at = ''\n",
    "ats = ''\n",
    "bt = ''\n",
    "\n",
    "api_key = ''\n",
    "api_secret_key = ''\n",
    "access_token = ''\n",
    "access_token_secret = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc2cf3b",
   "metadata": {},
   "source": [
    "# Scarping time ranges for tweets parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26683d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = [str(i)[:-9] + 'T00:00:00Z' for i in pd.date_range(start='11/01/2022', periods=150)]\n",
    "\n",
    "master_ = pd.concat(master, axis=0)\n",
    "pairs_arr = pd.DataFrame({'start':dates[:-1], 'end':dates[1:]})\n",
    "pairs_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbb51c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_BEARER_TOKEN = bt\n",
    "client = tweepy.Client(bearer_token=MY_BEARER_TOKEN)\n",
    "\n",
    "counter = 0\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for search_query in tqdm(['balenciaga']):\n",
    "    for i in range(pairs_arr.shape[0]):\n",
    "\n",
    "        try:\n",
    "            tweets = client.get_all_tweets_count(query=search_query,\n",
    "                                                 start_time=pairs_arr['start'][i],\n",
    "                                                 end_time=pairs_arr['end'][i],\n",
    "                                                 granularity='minute'\n",
    "                                                 )\n",
    "            df = pd.DataFrame(tweets.data)\n",
    "            print(search_query, df['tweet_count'].sum())\n",
    "\n",
    "            df['search_query'] = search_query\n",
    "\n",
    "            counter += df['tweet_count'].sum()\n",
    "\n",
    "            dfs.append(df)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print('Waiting mode')\n",
    "            time.sleep(900)\n",
    "\n",
    "            tweets = client.get_all_tweets_count(query=search_query,\n",
    "                                                 start_time=pair[0],\n",
    "                                                 end_time=pair[1],\n",
    "                                                 granularity='minute'\n",
    "                                                 )\n",
    "            df = pd.DataFrame(tweets.data)\n",
    "            print(search_query, df['tweet_count'].sum())\n",
    "\n",
    "            df['search_query'] = search_query\n",
    "\n",
    "            counter += df['tweet_count'].sum()\n",
    "\n",
    "            dfs.append(df)\n",
    "\n",
    "\n",
    "dfs = pd.concat(dfs, axis=0)\n",
    "dfs.to_pickle('time_ranges.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc39353",
   "metadata": {},
   "source": [
    "Creating df_all dataframe, that contains rows labeled with timeperiod based on tweet count thresholds.\n",
    "\n",
    "- timeperiod = 1: Marks rows with cumulative tweet counts exceeding 450 or adjacent to rows exceeding the threshold.\n",
    "- timeperiod = 2: Marks rows with isolated large jumps in cumulative counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4457ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = ['balenciaga']\n",
    "\n",
    "df_all = []\n",
    "\n",
    "for tag in tags:\n",
    "    df_local = dfs.copy().reset_index(drop=True)\n",
    "\n",
    "    counter = 0\n",
    "    counter2 = 0\n",
    "\n",
    "    for i in tqdm(range(1, df_local.shape[0])):\n",
    "        counter2 += df_local['tweet_count'][i]\n",
    "        \n",
    "        if df_local['tweet_count'][i] >= 450:\n",
    "            if df_local['tweet_count'][i-1] < 450:\n",
    "                df_local.at[i-1, 'timeperiod'] = 1\n",
    "            df_local.at[i, 'timeperiod'] = 1\n",
    "            counter = 0\n",
    "            counter2 = 0\n",
    "        elif counter2 >= 450 and counter < 450 and counter > 0:\n",
    "            df_local.at[i-1, 'timeperiod'] = 1\n",
    "            counter = df_local['tweet_count'][i]\n",
    "            counter2 = df_local['tweet_count'][i]\n",
    "        elif counter2 < 450 and counter < 450:\n",
    "            counter += df_local.tweet_count[i]\n",
    "        elif counter == 0 and counter2 > 450:\n",
    "            df_local.at[i, 'timeperiod'] = 2\n",
    "            counter = 0\n",
    "            counter2 = 0\n",
    "        \n",
    "    df_all.append(df_local)\n",
    "    \n",
    "df_all = pd.concat(df_all, axis = 0)\n",
    "df_all.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659a39ec",
   "metadata": {},
   "source": [
    "No rows have timeperiod = 2, indicating there were no isolated spikes or non-contiguous periods where cumulative tweet counts exceeded 450."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "29bfaf90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>end</th>\n",
       "      <th>start</th>\n",
       "      <th>tweet_count</th>\n",
       "      <th>search_query</th>\n",
       "      <th>timeperiod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [end, start, tweet_count, search_query, timeperiod]\n",
       "Index: []"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all[df_all['timeperiod'] == 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c64164",
   "metadata": {},
   "source": [
    "Retrieves tweets within time periods scarped "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777f8d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_BEARER_TOKEN = bt\n",
    "import time\n",
    "\n",
    "def extract_geo(s):\n",
    "    try:\n",
    "        a = s['place_id']\n",
    "        return a\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "df_arr_all = []\n",
    "counter = 0\n",
    "\n",
    "for i in tqdm(range(df_all.shape[0])):\n",
    "    \n",
    "    print(df_all['start'][i], df_all['end'][i])\n",
    "    \n",
    "    try:\n",
    "        client = tweepy.Client(bearer_token=MY_BEARER_TOKEN)\n",
    "\n",
    "        tweets = client.search_all_tweets(query=df_all['search_query'][i],\n",
    "                                         start_time=df_all['start'][i],\n",
    "                                         end_time=df_all['end'][i],\n",
    "                                         tweet_fields = [\"created_at\", \"text\", \"source\", 'author_id', 'public_metrics',\n",
    "                                                        'geo', 'entities', 'lang'],\n",
    "                                         user_fields = [\"name\", \"username\", \"location\", \"verified\", \"description\"],\n",
    "                                         place_fields = ['full_name', 'id', 'country', 'country_code', 'geo', 'name',\n",
    "                                                        'place_type'],\n",
    "                                         max_results = 500,\n",
    "                                         expansions=['author_id', 'geo.place_id']\n",
    "                                         )\n",
    "    except:\n",
    "        client = tweepy.Client(bearer_token=MY_BEARER_TOKEN)\n",
    "\n",
    "        tweets = client.search_all_tweets(query=ch['search_query'][i],\n",
    "                                         start_time=ch['start'][i],\n",
    "                                         end_time=ch['end'][i],\n",
    "                                         tweet_fields = [\"created_at\", \"text\", \"source\", 'author_id', 'public_metrics',\n",
    "                                                        'geo', 'entities', 'lang'],\n",
    "                                         user_fields = [\"name\", \"username\", \"location\", \"verified\", \"description\"],\n",
    "                                         place_fields = ['full_name', 'id', 'country', 'country_code', 'geo', 'name',\n",
    "                                                        'place_type'],\n",
    "                                         max_results = 500,\n",
    "                                         expansions=['author_id', 'geo.place_id']\n",
    "                                         )\n",
    "    counter += 1\n",
    "    time.sleep(1)\n",
    "    df_arr = []\n",
    "    if counter == 290:\n",
    "        time.sleep(900)\n",
    "        counter = 0\n",
    "\n",
    "    if tweets.meta['result_count'] > 0:\n",
    "\n",
    "        print(f\"Were found additionally {tweets.meta['result_count']} tweets\")\n",
    "\n",
    "        for el in tweets.data:\n",
    "            df_arr.append([el.id, el.text, el.author_id, extract_geo(el.geo), el.created_at, \n",
    "                           el.lang, el.public_metrics.get('retweet_count', 0), el.public_metrics.get('reply_count', 0),\n",
    "                           el.public_metrics.get('like_count', 0), el.public_metrics.get('quote_count', 0)])\n",
    "\n",
    "        df = pd.DataFrame(df_arr)\n",
    "\n",
    "        df.columns = ['tweet_id', 'text', 'author_id', 'geo', 'created_at', 'lang', 'retweet_count', 'reply_count',\n",
    "                     'like_count', 'quote_count']\n",
    "\n",
    "        df['author_location'] = '-1'\n",
    "        df['country'] = 'No Country\n",
    "        df['query'] = df_all['search_query'][i]\n",
    "\n",
    "        df_arr_all.append(df)\n",
    "\n",
    "pd.concat(df_arr_all, axis=0).to_pickle('balenciaga_tweets.pkl')\n",
    "dff = pd.concat(df_arr_all, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee67c3e",
   "metadata": {},
   "source": [
    "Retriving user's information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "17ee36ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1123166102995865600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1950852385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50073553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1388702657792159746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49987009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58067</th>\n",
       "      <td>198146259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58068</th>\n",
       "      <td>704059993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58069</th>\n",
       "      <td>1526758613775155200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58070</th>\n",
       "      <td>1235772718043316226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58071</th>\n",
       "      <td>1304480104446177280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58072 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 author_id\n",
       "0      1123166102995865600\n",
       "1               1950852385\n",
       "2                 50073553\n",
       "3      1388702657792159746\n",
       "4                 49987009\n",
       "...                    ...\n",
       "58067            198146259\n",
       "58068            704059993\n",
       "58069  1526758613775155200\n",
       "58070  1235772718043316226\n",
       "58071  1304480104446177280\n",
       "\n",
       "[58072 rows x 1 columns]"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = dff['author_id'].unique()\n",
    "df = pd.DataFrame({'author_id':users})\n",
    "users_prev = df_prev['author_id'].unique()\n",
    "df = df[~df['author_id'].isin(users_prev)].reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4328be",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'Authorization': f\"Bearer {bt}\",\n",
    "}\n",
    "\n",
    "profile_arr = []\n",
    "counter = 0\n",
    "\n",
    "for i in tqdm(range(df.shape[0] // 100 + 1)):\n",
    "    if counter == 295:\n",
    "        time.sleep(900)\n",
    "        counter = 0\n",
    "        \n",
    "    author_ids = ','.join([str(i) for i in df.iloc[i * 100:(i+1)*100, :]['author_id'].tolist()])\n",
    "    s = f\"https://api.twitter.com/2/users?ids={author_ids}&user.fields=location,name\"\n",
    "    response = requests.get(s, headers=headers)\n",
    "    r = json.loads(response.text)['data']\n",
    "    profile_arr.append(pd.DataFrame(r))\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "24112b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(profile_arr, axis = 0).reset_index(drop=True)\n",
    "df = df.drop(columns = ['withheld']).drop_duplicates().reset_index(drop=True)\n",
    "df['loc1'] = df['location'].str.lower().fillna('no country')\n",
    "df['country'] = 'no country'\n",
    "df['id'] = df['id'].apply(int)\n",
    "df.to_pickle('users_balenciaga.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d572a02",
   "metadata": {},
   "source": [
    "Merging user's information and tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e713dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff2 = dff.merge(df.rename(columns = {\"id\":'author_id'}), how = 'left', on = 'author_id')\n",
    "dff2.to_pickle('balenciaga.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
